{
    "collab_server" : "",
    "contents" : "#' Fit distributions to elicited probabilities \n#' \n#' Takes elicited probabilities as inputs, and fits parametric distributions\n#' using least squares on the cumulative distribution function. If separate\n#' judgements from multiple experts are specified, the function will fit one\n#' set of distributions per expert.\n#' \n#' \n#' @param vals A vector of elicited values for one expert, or a matrix of\n#' elicited values for multiple experts (one column per expert). Note that the\n#' an elicited judgement about X should be of the form P(X<= vals[i,j]) =\n#' probs[i,j]\n#' @param probs A vector of elicited probabilies for one expert, or a matrix of\n#' elicited values for multiple experts (one column per expert). A single\n#' vector can be used if the probabilities are the same for each expert. For\n#' each expert, the smallest elicited probability must be less than 0.4, and\n#' the largest elicited probability must be greater than 0.6.\n#' @param lower A single lower limit for the uncertain quantity X, or a vector\n#' of different lower limits for each expert. Specifying a lower limit will\n#' allow the fitting of distributions bounded below.\n#' @param upper A single upper limit for the uncertain quantity X, or a vector\n#' of different lower limits for each expert. Specifying both a lower limit and\n#' an upper limit will allow the fitting of a Beta distribution.\n#' @param weights A vector or matrix of weights corresponding to vals if\n#' weighted least squares is to be used in the parameter fitting.\n#' @param tdf The number of degrees of freedom to be used when fitting a\n#' t-distribution.\n#' @return An object of class \\code{elicitation}. This is a list containing the elements\n#' \\item{Normal}{Parameters of the fitted normal distributions.}\n#' \\item{Student.t}{Parameters of the fitted t distributions. Note that (X -\n#' location) / scale has a standard t distribution. The degrees of freedom is\n#' not fitted; it is specified as an argument to \\code{fitdist}.}\n#' \\item{Gamma}{Parameters of the fitted gamma distributions. Note that E(X) =\n#' shape / rate.} \n#' \\item{Log.normal}{Parameters of the fitted log normal\n#' distributions: the mean and standard deviation of log X.}\n#' \\item{Log.Student.t}{Parameters of the fitted log student t distributions.\n#' Note that (log(X) - location) / scale has a standard t distribution. The\n#' degrees of freedom is not fitted; it is specified as an argument to\n#' \\code{fitdist}.} \n#' \\item{Beta}{Parameters of the fitted beta distributions. X\n#' is scaled to the interval [0,1] via Y = (X - \\code{lower})/(\\code{upper} -\n#' \\code{lower}), and E(Y) = shape1 / (shape1 + shape2).} \n#' \\item{ssq}{Sum of\n#' squared errors for each fitted distribution and expert. Each error is the\n#' different between an elicited cumulative probability and the corresponding\n#' fitted cumulative probability.} \n#' \\item{best.fitting}{The best fitting\n#' distribution for each expert, determined by the smallest sum of squared\n#' errors.} \n#' \\item{vals}{The elicited values used to fit the distributions.}\n#' \\item{probs}{The elicited probabilities used to fit the distributions.}\n#' \\item{limits}{The lower and upper limits specified by each expert (+/- Inf\n#' if not specified).}\n#' @note The least squares parameter values are found numerically using the\n#' \\code{optim} command. Starting values for the distribution parameters are\n#' chosen based on a simple normal approximation: linear interpolation is used\n#' to estimate the 0.4, 0.5 and 0.6 quantiles, and starting parameter values\n#' are chosen by setting E(X) equal to the 0.5th quantile, and Var(X) = (0.6\n#' quantile - 0.4 quantile)^2 / 0.25. Note that the arguments \\code{lower} and\n#' \\code{upper} are not included as elicited values on the cumulative\n#' distribution function. To include a judgement such as P(X<=a)=0, the values\n#' a and 0 must be included in \\code{vals} and \\code{probs} respectively.\n#' @author Jeremy Oakley <j.oakley@@sheffield.ac.uk>\n#' @examples\n#' \\dontrun{\n#' # One expert, with elicited probabilities\n#' # P(X<20)=0.25, P(X<30)=0.5, P(X<50)=0.75\n#' # and X>0.\n#' v <- c(20,30,50)\n#' p <- c(0.25,0.5,0.75)\n#' fitdist(vals=v, probs=p, lower=0)\n#' \n#' # Now add a second expert, with elicited probabilities\n#' # P(X<55)=0.25, P(X<60=0.5), P(X<70)=0.75\n#' v <- matrix(c(20,30,50,55,60,70),3,2)\n#' p <- c(0.25,0.5,0.75)\n#' fitdist(vals=v, probs=p, lower=0)\n#' \n#' # Two experts, different elicited quantiles and limits.\n#' # Expert A: P(X<50)=0.25, P(X<60=0.5), P(X<65)=0.75, and provides bounds 10<X<100\n#' # Expert B: P(X<40)=0.33, P(X<50=0.5), P(X<60)=0.66, and provides bounds 0<X\n#' v <- matrix(c(50,60,65,40,50,60),3,2)\n#' p <- matrix(c(.25,.5,.75,.33,.5,.66),3,2)\n#' l <- c(10,0)\n#' u <- c(100, Inf)\n#' fitdist(vals=v, probs=p, lower=l, upper=u)\n#' }\n#' @import stats\n#' @export\n#' \n#' \nfitdist <-\nfunction(vals, probs, lower = -Inf, upper = Inf, weights = 1, tdf = 3){\n\t\n\tif(is.matrix(vals)==F){vals<-matrix(vals, nrow = length(vals), ncol = 1)}\n\tif(is.matrix(probs)==F){probs <- matrix(probs, nrow = nrow(vals), ncol = ncol(vals))}\n\tif(is.matrix(weights)==F){weights <- matrix(weights, nrow = nrow(vals), ncol = ncol(vals))}\n\tif(length(lower)==1){lower <- rep(lower, ncol(vals))}\n\tif(length(upper)==1){upper <- rep(upper, ncol(vals))}\n\tif(length(tdf)==1){tdf <- rep(tdf, ncol(vals))}\n\t\n  \n\t\n\tn.experts <- ncol(vals)\n\tnormal.parameters <- matrix(NA, n.experts, 2)\n\tt.parameters <- matrix(NA, n.experts, 3)\n\tgamma.parameters <- matrix(NA, n.experts, 2)\n\tlognormal.parameters <- matrix(NA, n.experts, 2)\n\tlogt.parameters <- matrix(NA, n.experts, 3)\n\tbeta.parameters <- matrix(NA, n.experts, 2)\n\tssq<-matrix(NA, n.experts, 6)\n\texpertnames <- paste(\"expert.\", LETTERS[1:n.experts], sep=\"\")\n\t\n\tlimits <- data.frame(lower = lower, upper = upper)\n\trow.names(limits) <- expertnames\n\t\n\tfor(i in 1:n.experts){\n\t\tif (min(probs[,i]) > 0.4 ){stop(\"smallest elicited probability must be less than 0.4\")}\n\t\tif (min(probs[,i]) < 0 | max(probs[,i]) > 1 ){stop(\"probabilities must be between 0 and 1\")}\n\t\tif (max(probs[,i]) < 0.6 ){stop(\"largest elicited probability must be greater than 0.6\")}\n    if (min(vals[,i]) < lower[i]){stop(\"elicited parameter values cannot be smaller than lower parameter limit\")}\n\t\tif (max(vals[,i]) > upper[i]){stop(\"elicited parameter values cannot be greater than upper parameter limit\")}\n\t\tif (tdf[i] <= 0 ){stop(\"Student-t degrees of freedom must be greater than 0\")}\n\t\tif (min(probs[-1,i] - probs[-nrow(probs),i]) <= 0 ){stop(\"probabilities must be specified in ascending order\")}\n\t\tif (min(vals[-1,i] - vals[-nrow(vals),i]) <= 0 ){stop(\"parameter values must be specified in ascending order\")}\n    \n\t  minprob <- min(probs[, i])\n\t  maxprob <- max(probs[, i])\n\t\t\n\t  q.fit <- approx(x = probs[,i], y = vals[,i], xout = c(0.4, 0.5, 0.6))$y\n\t  l <- q.fit[1]\n\t  u <- q.fit[3]\n\t  \n\t  if(minprob > 0 & maxprob < 1){\n\t\t  minvals <- min(vals[, i])\n\t\t  maxvals <- max(vals[, i])\n\t\t  minq <- qnorm(minprob)\n\t\t  maxq <- qnorm(maxprob)\n\t\t  m <- (minvals * maxq - maxvals * minq) / (maxq - minq)\n\t\t  v <- ((maxvals - minvals) / (maxq - minq))^2\n\t\t}else{\n\t\t  m <- q.fit[2]\n\t\t  v<- (u - l)^2 / 0.25\n\t\t} \n\t\n\t\tnormal.fit <- optim(c(m, 0.5*log(v)), normal.error, values = vals[,i], probabilities = probs[,i], weights = weights[,i])   \n    normal.parameters[i,] <- c(normal.fit$par[1],exp(normal.fit$par[2]))\n    ssq[i,1] <- normal.fit$value\n\t\n\t\tt.fit <- optim(c(m, 0.5*log(v)), t.error, values = vals[,i], probabilities = probs[,i], weights = weights[,i], degreesfreedom = tdf[i])\n    \tt.parameters[i, 1:2] <- c(t.fit$par[1], exp(t.fit$par[2]))\n    \tt.parameters[i, 3] <- tdf[i]\n    \tssq[i,2] <- t.fit$value\n\t\n\t\n\t\tif(lower[i] > -Inf){\n\t\t\tvals.scaled1 <- vals[,i] - lower[i]\n\t\t\tm.scaled1 <- m - lower[i]\n\t\t\n\t\t\tgamma.fit<-optim(c(log(m.scaled1^2/v), log(m.scaled1/v)), gamma.error, values = vals.scaled1, probabilities = probs[,i], weights = weights[,i])\n    \t\tgamma.parameters[i,] <- exp(gamma.fit$par)\n    \t\tssq[i,3] <- gamma.fit$value\n    \t\t\n    \t\tstd<-((log(u)-log(l))/1.35)\n    \t\n    \t\tlognormal.fit <- optim(c(log(m.scaled1), log(std)), lognormal.error, values = vals.scaled1, probabilities = probs[,i], weights = weights[,i])\n    \t\tlognormal.parameters[i, 1:2] <- c(lognormal.fit$par[1], exp(lognormal.fit$par[2]))\n    \t\tssq[i,4] <- lognormal.fit$value\n    \t\n    \t\tlogt.fit <- optim(c(log(m.scaled1), log(std)), logt.error, values = vals.scaled1, probabilities = probs[,i], weights = weights[,i], degreesfreedom = tdf[i])\n    \t\tlogt.parameters[i,1:2] <- c(logt.fit$par[1], exp(logt.fit$par[2]))\n    \t\tlogt.parameters[i,3] <- tdf[i]\n    \t\tssq[i,5] <- logt.fit$value\n\t\t}\n\t\n\t\tif((lower[i] > -Inf) & (upper[i] < Inf)){\n\t\t\tvals.scaled2 <- (vals[,i] - lower[i]) / (upper[i] - lower[i])\n\t\t\tm.scaled2 <- (m - lower[i]) / (upper[i] - lower[i])\n\t\t\tv.scaled2 <- v / (upper[i] - lower[i])^2\n\t\t\n\t\t\talp <- abs(m.scaled2 ^3 / v.scaled2 * (1/m.scaled2-1) - m.scaled2)\n    \t\tbet <- abs(alp/m.scaled2 - alp)\n    \t\tif(identical(probs[, i], \n    \t\t             (vals[, i] - lower[i]) / (upper[i] - lower[i]))){\n    \t\t  alp <- bet <- 1\n    \t\t}\n    \t\tbeta.fit <- optim(c(log(alp), log(bet)), beta.error, values = vals.scaled2, probabilities = probs[,i], weights = weights[,i])\n    \t\tbeta.parameters[i,] <- exp(beta.fit$par)\n    \t\tssq[i,6] <- beta.fit$value\t\n\t\t\n\t\t}\n\t}\n\tdfn <- data.frame(normal.parameters)\n\tnames(dfn) <-c (\"mean\", \"sd\")\n\trow.names(dfn) <- expertnames\n\t\t\n\tdft <- data.frame(t.parameters)\n\tnames(dft) <-c (\"location\", \"scale\", \"df\")\n\trow.names(dft) <- expertnames\n\t\n\tdfg <- data.frame(gamma.parameters)\n\tnames(dfg) <-c (\"shape\", \"rate\")\n\trow.names(dfg) <- expertnames\n\t\n\tdfln <- data.frame(lognormal.parameters)\n\tnames(dfln) <-c (\"mean.log.X\", \"sd.log.X\")\n\trow.names(dfln) <- expertnames\n\t\n\tdflt <- data.frame(logt.parameters)\n\tnames(dflt) <-c (\"location.log.X\", \"scale.log.X\", \"df.log.X\")\n\trow.names(dflt) <- expertnames\n\t\n\tdfb <- data.frame(beta.parameters)\n\tnames(dfb) <-c (\"shape1\", \"shape2\")\n\trow.names(dfb) <- expertnames\n\t\n\tssq <- data.frame(ssq)\n\tnames(ssq) <- c(\"Normal\", \"Student-t\", \"Gamma\", \"Log normal\", \"Log Student-t\", \"Beta\")\n\trow.names(ssq) <- expertnames\n\t\n\tindex <- apply(ssq, 1, which.min)\n\tbest.fitting <- data.frame(best.fit=names(ssq)[index])\n\trow.names(best.fitting) <- expertnames\n  \n\tvals <- data.frame(vals)\n\tnames(vals) <- expertnames\n\t\n\tprobs <- data.frame(probs)\n\tnames(probs) <- expertnames\n\t\t\n  fit <- list(Normal = dfn, Student.t = dft, \n              Gamma = dfg, Log.normal = dfln, \n              Log.Student.t = dflt, Beta = dfb, ssq = ssq, \n              best.fitting = best.fitting, vals = t(vals), \n              probs = t(probs), limits = limits)\n  class(fit) <- \"elicitation\"\n  fit\n}\n",
    "created" : 1475229097504.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "876625730",
    "id" : "6257D7EC",
    "lastKnownWriteTime" : 1475229118,
    "last_content_update" : 1475229118258,
    "path" : "~/Dropbox/Research/R packages/SHELF/SHELF1.2.0.9001/R/fitdist.R",
    "project_path" : "R/fitdist.R",
    "properties" : {
    },
    "relative_order" : 6,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}